{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LgvjgMiXsC0P",
        "s31T5pyMqzaA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import requests\n",
        "import gradio as gr\n",
        "import yfinance as yf"
      ],
      "metadata": {
        "id": "V_cbXUFjswQl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento"
      ],
      "metadata": {
        "id": "LgvjgMiXsC0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/near-protocol_2020-05-11_2025-05-10.csv')\n",
        "data['Date'] = pd.to_datetime(data['Start'])\n",
        "data.insert(0, 'Date', data.pop('Date'))\n",
        "data.drop(['Start', 'End'], axis=1, inplace=True)\n",
        "\n",
        "ses_model = SimpleExpSmoothing(data['Market Cap']).fit(smoothing_level=0.2, optimized=False)\n",
        "data['Market Cap Smooth'] = ses_model.fittedvalues\n",
        "\n",
        "# plt.figure(figsize=(15, 6))\n",
        "# plt.plot(data['Market Cap'], label='Original', alpha=0.5)\n",
        "# plt.plot(data['Market Cap Smooth'], label='Exponential Smoothing')\n",
        "# plt.legend()\n",
        "# plt.title('Suavizado exponencial')\n",
        "# plt.show()\n",
        "\n",
        "for col in ['Open', 'High', 'Low', 'Close', 'Volume', 'Market Cap', 'Market Cap Smooth']:\n",
        "    data[f'Pct Diff {col}'] = data[col].pct_change()\n",
        "\n",
        "# data.to_csv('data.csv', index=False)\n",
        "\n",
        "data.dropna(inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "data.to_csv('data_preprocesed.csv', index=False)"
      ],
      "metadata": {
        "id": "LrqYQI04sCii"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento"
      ],
      "metadata": {
        "id": "s31T5pyMqzaA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "csGhgmu2onxN"
      },
      "outputs": [],
      "source": [
        "# Config\n",
        "INPUT_WINDOW = 56\n",
        "PREDICTION_HORIZON = 7\n",
        "N_SPLITS = 5\n",
        "\n",
        "# Cargar datos\n",
        "data = pd.read_csv('/content/data_preprocesed.csv')\n",
        "data.drop(['Market Cap', 'Pct Diff Market Cap'], axis=1, inplace=True)\n",
        "data.sort_values(\"Date\", inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Features porcentuales\n",
        "features_pct = [col for col in data.columns if col.startswith('Pct Diff ')]\n",
        "\n",
        "# Crear ventanas de entrenamiento\n",
        "def create_features_and_labels(df, feature_columns, input_window, prediction_horizon):\n",
        "    X, y = [], []\n",
        "    for i in range(len(df) - input_window - prediction_horizon):\n",
        "        window = df[feature_columns].iloc[i:i + input_window].values.flatten()\n",
        "        last_high = df['High'].iloc[i + input_window - 1]\n",
        "        future_high = df['High'].iloc[i + input_window + prediction_horizon - 1]\n",
        "        label = int(future_high > last_high)\n",
        "        X.append(window)\n",
        "        y.append(label)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_pct, y_pct = create_features_and_labels(data, features_pct, INPUT_WINDOW, PREDICTION_HORIZON)\n",
        "\n",
        "# Escalar\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_pct)\n",
        "\n",
        "# Modelo\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    class_weight='balanced_subsample'\n",
        ")\n",
        "\n",
        "# Entrenamiento final con todos los datos\n",
        "rf_model.fit(X_scaled, y_pct)\n",
        "\n",
        "# Guardar modelo y scaler\n",
        "with open('rf_model.pkl', 'wb') as f:\n",
        "    pickle.dump(rf_model, f)\n",
        "\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio"
      ],
      "metadata": {
        "id": "54pCUwiUzGmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración\n",
        "INPUT_WINDOW = 56\n",
        "\n",
        "# Cargar modelo y scaler\n",
        "with open(\"rf_model.pkl\", \"rb\") as f:\n",
        "    rf_model = pickle.load(f)\n",
        "\n",
        "with open(\"scaler.pkl\", \"rb\") as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "# Descargar y procesar datos desde Yahoo Finance\n",
        "def fetch_and_process_data(ticker=\"BTC-USD\", period=\"90d\", interval=\"1d\"):\n",
        "    df = yf.download(ticker, period=period, interval=interval, progress=False)\n",
        "\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.droplevel(1)\n",
        "\n",
        "    if df.empty:\n",
        "        raise ValueError(f\"No se pudieron obtener datos para '{ticker}' desde Yahoo Finance.\")\n",
        "\n",
        "    df[\"Market Cap\"] = df[\"Close\"] * df[\"Volume\"]\n",
        "    df.reset_index(inplace=True)\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.date\n",
        "\n",
        "    df = df[[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Market Cap\"]]\n",
        "\n",
        "    for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Market Cap\"]:\n",
        "        df[f\"Pct Diff {col}\"] = df[col].pct_change()\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "    df.set_index(\"Date\", inplace=True)\n",
        "    df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Obtener los últimos INPUT_WINDOW días\n",
        "def get_latest_window(symbol=\"BTC-USD\"):\n",
        "    df = fetch_and_process_data(symbol)\n",
        "    if len(df) < INPUT_WINDOW:\n",
        "        raise ValueError(f\"Se requieren al menos {INPUT_WINDOW} días de datos. Solo se obtuvieron {len(df)}.\")\n",
        "    return df.tail(INPUT_WINDOW)\n",
        "\n",
        "# Crear ventana de entrada para el modelo\n",
        "def create_input_window(df):\n",
        "    df.columns = df.columns.astype(str)\n",
        "    feature_cols = [col for col in df.columns if col.startswith(\"pct_diff\")]\n",
        "    X = df[feature_cols].iloc[-INPUT_WINDOW:].values.flatten().reshape(1, -1)\n",
        "    expected_features = INPUT_WINDOW * len(feature_cols)\n",
        "    if X.shape[1] != expected_features:\n",
        "        raise ValueError(f\"Se esperaban {expected_features} características, pero se recibieron {X.shape[1]}.\")\n",
        "    return X, df\n",
        "\n",
        "# Función principal de predicción\n",
        "def predict_crypto(ticker_input):\n",
        "    try:\n",
        "        symbol = ticker_input.strip().upper()\n",
        "        df = get_latest_window(symbol)\n",
        "        X_input, df_processed = create_input_window(df)\n",
        "        X_scaled = scaler.transform(X_input)\n",
        "\n",
        "        pred = rf_model.predict(X_scaled)[0]\n",
        "        proba = rf_model.predict_proba(X_scaled)[0]\n",
        "\n",
        "        label = \"Subirá\" if pred == 1 else \"Bajará\"\n",
        "        prob_str = f\"Probabilidad de subida: {proba[1]:.2%}\\nProbabilidad de bajada: {proba[0]:.2%}\"\n",
        "\n",
        "        # Generar gráfico de precios\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        df_processed[\"close\"].tail(INPUT_WINDOW).plot(title=f\"{symbol} - Últimos {INPUT_WINDOW} días\", grid=True)\n",
        "        plt.xlabel(\"Fecha\")\n",
        "        plt.ylabel(\"Precio de cierre (USD)\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"price_plot.png\")\n",
        "        plt.close()\n",
        "\n",
        "        return label, prob_str, \"price_plot.png\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", None, None\n",
        "\n",
        "# Interfaz de usuario con Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=predict_crypto,\n",
        "    inputs=gr.Textbox(label=\"Ticker (Yahoo Finance)\", placeholder=\"Ej. BTC-USD, ETH-USD, NEAR-USD\"),\n",
        "    outputs=[\n",
        "        gr.Label(label=\"Predicción de dirección\"),\n",
        "        gr.Textbox(label=\"Probabilidades\"),\n",
        "        gr.Image(label=\"Gráfico de precios\")\n",
        "    ],\n",
        "    title=\"Predicción de criptomonedas con Random Forest\",\n",
        "    description=(\n",
        "        \"Introduce un ticker válido de Yahoo Finance (BTC-USD, ETH-USD, NEAR-USD) para predecir si el precio subirá o bajará en los próximos días usando porcentajes de cambio como entrada del modelo.\"\n",
        "    ),\n",
        "    examples=[[\"BTC-USD\"], [\"ETH-USD\"], [\"NEAR-USD\"]]\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "j1I8SfrxwyL1",
        "outputId": "f8922771-13e6-4c40-dc4a-eceb9a8ce217"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://aaca3222a46d30353b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://aaca3222a46d30353b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YPQybKmCpGfi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}